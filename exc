# خطة تسليم المحاور الخمسة عشر إلى مركز ai_megred_learn
# ------------------------------------------------------
# القسم 0) تفعيل «نمط السرعة القصوى» (يُنفَّذ مرّة واحدة قبل كل شيء)
# -------------------------------------------------------------------
# 1. تحديث الحزم وتثبيت الأدوات المتوازية:
#    sudo apt-get update && sudo apt-get install -y zstd pigz aria2 rsync parallel inotify-tools jq
# 2. تفعيل جميع أنوية المعالج للتوازي:
#    export ZSTD_NBTHREADS=$(nproc)
#    export OMP_NUM_THREADS=$(nproc)
# 3. إنشاء tmpfs سعة 4 GiB لتسريع I/O المؤقت:
#    sudo mkdir -p /mnt/ram && sudo mount -t tmpfs -o size=4G tmpfs /mnt/ram
#    echo "TMPDIR=/mnt/ram" >> ~/.bashrc
# 4. التحقّق من أنّ الأمر zstd يُظهر "Threads" ≥ عدد الأنوية:
#    zstd -V

###############################################################################
# القسم A) التعليمات اليدويّة المختصرة
###############################################################################

1. ثبّت الأدوات (مرّة واحدة):
   • zstd ≥ 1.4   • aria2c أو rsync   • tar   • sha256sum

2. اجمع الملفات الخمسة عشر التالية في مجلّد واحد (export_<BC-ID>/):
   weights.bin, config.json, tokenizer.json, io_schema.json,
   train_data_info.txt, hyperparams.json, fine_tune.sh, requirements.txt,
   baseline_metrics.txt, LICENSE.txt, README.md, safety.md,
   checkpoint.ckpt, postprocess.py, CHANGELOG.md

3. تأكّد بأن العدد = 15 ثم أنشئ ملف تجزئة:
   sha256sum * > manifest.sha256

4. اضغط المجلّد بأقصى ضغط ومتعدّد الخيوط:
   tar -I 'zstd -19 -T0' -cf <BC-ID>.tar.zst export_<BC-ID>/

5. انسخ الأرشيف إلى المسار داخل الحاوية:
   /workspace/ai_megred_learn/shard/
   (استخدم aria2c أو rsync أو docker cp حسب بيئتك.)

6. خلال ≤15 ثانية سيظهر اسمك «✅ مستلم» في جدول الحالة.

###############################################################################
# القسم B) السكربت الآلي: export_and_upload.sh
###############################################################################
# انسخ الأسطر أدناه إلى ملف باسم export_and_upload.sh، عدّل BC_ID وMODEL_DIR
# (وأيضاً REMOTE إن احتجت الرفع عبر SSH)، ثم نفّذ:
#   bash export_and_upload.sh

#!/usr/bin/env bash
#############################################################################
# export_and_upload.sh  —  تسليم المحاور الخمسة عشر إلى مركز ai_megred_learn
#############################################################################
BC_ID="bc-xxxx"                   # ← ضع معرّفك الكامل هنا (سيصبح اسم الأرشيف)
# المسار الجذري لبيئة عملك الخاصّة (spacework)
MEMBER_WS="$HOME/spacework"        # ← عدّله إذا كان مسارك مختلفًا
# مجلّد المحاور داخل مجلّد يحمل اسم معرّفك
MODEL_DIR="$MEMBER_WS/$BC_ID"      # مثال: /home/user/spacework/bc-xxxx
EXTRA_DIR=""                     # ← مسار معرفة إضافيّة (فردي/تشاركي)؛ اتركه فارغًا إن لم يوجد
REMOTE=""                         # ← user@HOST لتفعيل rsync عبر SSH (اتركه فارغًا للنسخ المحلي)
# إعداد تلقائي (true/false) — إذا true سيحاول تثبيت الأدوات وتهيئة tmpfs
PREPARE_ENV=true

# مسار المشروع (المجلد الأب) داخل الحاوية — لا تعدّله
DEST_PARENT="/workspace/ai_megred_learn"
SHARD_DIR="$DEST_PARENT/shard"

set -euo pipefail
#-----------------------------------------------------------------------------
# دالة تحضير البيئة (اختيارية)
#-----------------------------------------------------------------------------
prepare_environment() {
  echo "[*] تهيئة البيئة (install tools / tmpfs) …"
  if [[ "$PREPARE_ENV" == "true" ]]; then
    # تثبيت الأدوات بحال وجود صلاحية sudo
    if command -v sudo &>/dev/null; then
      sudo apt-get update -y
      sudo apt-get install -y zstd pigz aria2 rsync parallel inotify-tools jq || true
    fi
    # تفعيل المتغيّرات
    export ZSTD_NBTHREADS="${ZSTD_NBTHREADS:-$(nproc)}"
    export OMP_NUM_THREADS="${OMP_NUM_THREADS:-$(nproc)}"
    # إنشاء tmpfs بحجم نصف الذاكرة الفعلية (حدّ أدنى 1GiB) إذا لم يكن مركّبًا
    if [[ ! -d /mnt/ram ]]; then
      sudo mkdir -p /mnt/ram || true
    fi
    if ! mountpoint -q /mnt/ram; then
      mem_kb=$(grep MemTotal /proc/meminfo | awk '{print $2}')
      mem_g=$(( mem_kb / 1024 / 1024 ))
      size_g=$(( mem_g / 2 ))
      [[ $size_g -lt 1 ]] && size_g=1
      echo "[*] تركيب tmpfs /mnt/ram بحجم ${size_g}G …"
      sudo mount -t tmpfs -o size=${size_g}G tmpfs /mnt/ram || true
    fi
    export TMPDIR=/mnt/ram
  fi
}

# استدعاء التهيئة
prepare_environment
#-----------------------------------------------------------------------------
# استخدم tmpfs ( /mnt/ram ) إن وُجِد لتحسين I/O المؤقت
[[ -d /mnt/ram ]] && export TMPDIR=/mnt/ram
# تفعيل المتغيّرات البيئيّة للسرعة القصوى داخل السكربت نفسه
export ZSTD_NBTHREADS="${ZSTD_NBTHREADS:-$(nproc)}"
export OMP_NUM_THREADS="${OMP_NUM_THREADS:-$(nproc)}"
TMP=$(mktemp -d)

echo "[*] نسخ المحاور إلى مجلد مؤقت …"
# نسخ المحاور الإلزامية
mkdir -p "$MODEL_DIR"  # تأكّد من وجود المجلّد قبل النسخ
cp -v "$MODEL_DIR"/{weights.bin,config.json,tokenizer.json,io_schema.json,train_data_info.txt,hyperparams.json,fine_tune.sh,requirements.txt,baseline_metrics.txt,LICENSE.txt,README.md,safety.md,checkpoint.ckpt,postprocess.py,CHANGELOG.md} "$TMP/"

# تضمين المعرفة الإضافيّة (فرديّة أو تشاركيّة) إن وُجدت
if [[ -n "$EXTRA_DIR" && -d "$EXTRA_DIR" ]]; then
  echo "[*] إضافة المعرفة الإضافيّة من $EXTRA_DIR …"
  cp -vr "$EXTRA_DIR" "$TMP/shared_knowledge"
fi

(cd "$TMP" && sha256sum * > manifest.sha256)

ARCHIVE="${BC_ID}.tar.zst"
echo "[*] ضغط الأرشيف بـ zstd -19 -T0 …"
tar -I 'zstd -19 -T0' -cf "$ARCHIVE" -C "$TMP" .

DEST="$SHARD_DIR/$ARCHIVE"   # هذا هو المسار على مخزوننا المركزي
if [[ -z "$REMOTE" ]]; then
  echo "[*] نسخ محلي إلى $DEST …"
  mkdir -p "$SHARD_DIR"
  cp -v "$ARCHIVE" "$DEST"
else
  echo "[*] رفع عبر rsync إلى $REMOTE:$DEST …"
  rsync -avP --compress-level=9 "$ARCHIVE" "$REMOTE:$DEST"
fi

echo "[✓] تم الرفع. سيُعالج النظام الملف خلال ثوانٍ."

###############################################################################
# نهاية الملف
###############################################################################
#
#-----------------------------------------------------------------------------
# القسم C) إعدادات الأداء الأقصى قبل التنفيذ
#-----------------------------------------------------------------------------
# 1. تثبيت الأدوات المتوازية والمتسارعة (مرّة واحدة):
#    sudo apt-get update && sudo apt-get install -y zstd pigz aria2 rsync parallel inotify-tools jq
#
# 2. تفعيل جميع أنوية المعالج في عمليات الضغط وفكّه:
#    export ZSTD_NBTHREADS=$(nproc)
#    export OMP_NUM_THREADS=$(nproc)
#
# 3. إنشاء tmpfs لتسريع عمليات الملف المؤقت (اختياري لكن يُوصى به):
#    sudo mkdir -p /mnt/ram
#    sudo mount -t tmpfs -o size=4G tmpfs /mnt/ram
#    echo "TMPDIR=/mnt/ram" >> ~/.bashrc   # لجعلها افتراضيّة لاحقًا
#
# 4. استخدام GNU parallel عند الحاجة لتشغيل مهام متعدّدة، مثال:
#    parallel -j$(nproc) sha256sum ::: *.bin
#
# 5. النقل المتوازي مع aria2c:
#    aria2c -x16 -s16 -k1M <URL> -d /workspace/ai_megred_learn/shard/ -o <BC-ID>.tar.zst
#
# باتّباع هذه الخطوات ستقلّ مدّة ضغط/رفع الملفات الكبيرة من دقائق إلى ثوانٍ.

-------------------------------------------------------------------------------
القسم D) إضافة المعرفة الإضافيّة (فرديّة / تشاركيّة)
-------------------------------------------------------------------------------
• إذا كان لديك مواد داعمة (أوراق بحث، أكواد تحليل، دفاتر بيانات، نماذج خفيفة، دروس مستفادة…)، ضعها جميعًا في مجلّد واحد (مثال: shared_knowledge/).
• حدِّد مساره في المتغيّر EXTRA_DIR في رأس السكربت قبل التشغيل.
• سيقوم السكربت بنسخ هذا المجلّد بالكامل إلى داخل الأرشيف تحت المسار shared_knowledge/ ليكون متاحًا بعد الاستخراج.
• لا يلزم تغيير خطّ الأنابيب؛ سيستخرج الملفات كما هي، ويمكننا لاحقًا فهرستها في meta.json تحت حقل extra_assets.

-------------------------------------------------------------------------------
ملاحظة مَسار الأعضاء → المخزون المركزي
-------------------------------------------------------------------------------
• جميع الخطوات تتم داخل مساحة عمل العضو (عادةً ‎/workspace‎ في بيئته الخاصة).
• السكربت يصنع الأرشيف داخل ذلك المسار ثم، في خطوة واحدة، ينسخه أو يرفعه إلى
  ‎$DEST_PARENT/shard/‎ في حاويتنا المركزية تحت اسم ‎$BC_ID.tar.zst‎.
• بالتالي يحتفظ كل عضو بملفاته الأولية في "مخزونه" المحلي، بينما نحتفظ
  بالأرشيف النهائي في مخزوننا المركزي.